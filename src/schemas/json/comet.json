{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "definitions": {
    "AccessControlEntry": {
      "description": "Column level security policy to apply to the attribute.",
      "properties": {
        "grants": {
          "description": "user / groups / service accounts to which this security level is applied.\nex : user:me@mycompany.com,group:group@mycompany.com,serviceAccount:mysa@google-accounts.com",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "role": {
          "description": "This role to give to the granted users",
          "type": "string"
        }
      },
      "required": ["role", "grants"],
      "type": "object"
    },
    "Attribute": {
      "properties": {
        "accessPolicy": {
          "description": "Policy tag to assign to this attribute. Used for column level security",
          "type": "string"
        },
        "array": {
          "description": "Is it an array ?",
          "type": "boolean"
        },
        "attributes": {
          "description": "List of sub-attributes (valid for JSON and XML files only)",
          "items": {
            "$ref": "#/definitions/Attribute"
          },
          "type": "array"
        },
        "comment": {
          "description": "free text for attribute description",
          "type": "string"
        },
        "default": {
          "description": "Default value for this attribute when it is not present.",
          "type": "string"
        },
        "foreignKey": {
          "description": "If this attribute is a foreign key, reference to [domain.]table[.attribute]",
          "type": "string"
        },
        "ignore": {
          "description": "Should this attribute be ignored on ingestion. Default to false",
          "type": "boolean"
        },
        "metricType": {
          "description": "If present, what kind of stat should be computed for this field",
          "type": "string"
        },
        "name": {
          "description": "Attribute name as defined in the source dataset and as received in the file",
          "type": "string"
        },
        "position": {
          "$ref": "#/definitions/Position"
        },
        "privacy": {
          "description": "Should this attribute be applied a privacy transformation at ingestion time",
          "type": "string"
        },
        "rename": {
          "description": "If present, the attribute is renamed with this name",
          "type": "string"
        },
        "required": {
          "description": "Should this attribute always be present in the source",
          "type": "boolean"
        },
        "script": {
          "description": "Scripted field : SQL request on renamed column",
          "type": "string"
        },
        "tags": {
          "description": "Tags associated with this attribute",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "trim": {
          "$ref": "#/definitions/Trim"
        },
        "type": {
          "description": "semantic type of the attribute",
          "type": "string"
        }
      },
      "required": ["name", "type"],
      "type": "object"
    },
    "AutoJobDesc": {
      "properties": {
        "area": {
          "description": "Area where the data is located.\\nWhen using the BigQuery engine, the area corresponds to the dataset name we will be working on in this job.\\nWhen using the Spark engine, this is folder where the data should be store. Default value is \"business\"",
          "type": "string"
        },
        "coalesce": {
          "description": "When outputting files, should we coalesce it to a single file. Useful when CSV is the output format.",
          "type": "boolean"
        },
        "engine": {
          "$ref": "#/definitions/Engine"
        },
        "format": {
          "description": "output file format when using Spark engine. Ignored for BigQuery. Default value is \"parquet\"",
          "type": "string"
        },
        "name": {
          "description": "Job name. Must be set to the prefix of the filename. [JOBNAME].comet.yml ",
          "type": "string"
        },
        "tasks": {
          "items": {
            "$ref": "#/definitions/AutoTaskDesc",
            "description": "List of transform tasks to execute"
          },
          "type": "array"
        },
        "udf": {
          "description": "Register UDFs written in this JVM class when using Spark engine.\\nRegister UDFs stored at this location when using BigQuery engine",
          "type": "string"
        },
        "views": {
          "$ref": "#/definitions/MapString",
          "description": "Create temporary views using where the key is the view name and the map the SQL request corresponding to this view using the SQL engine supported syntax."
        }
      },
      "required": ["name", "tasks"],
      "type": "object"
    },
    "AutoTaskDesc": {
      "properties": {
        "area": {
          "description": "Target Area where domain / dataset will be stored.",
          "type": "string"
        },
        "assertions": {
          "$ref": "#/definitions/MapString",
          "description": "Assertions to check after Load / Transform has succeeded"
        },
        "domain": {
          "description": "Output domain in output Area (Will be the Database name in Hive or Dataset in BigQuery)",
          "type": "string"
        },
        "engine": {
          "$ref": "#/definitions/Engine",
          "description": "When BigQuery, The Spark engine is not required, the whole task is executed inside the datawarehouse, including when data saving in the table."
        },
        "partition": {
          "description": "List of columns used for partitioning the output.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "postsql": {
          "description": "List of SQL requests to executed after the main SQL request is run",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "presql": {
          "description": "List of SQL requests to executed before the main SQL request is run",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "rls": {
          "items": {
            "$ref": "#/definitions/RowLevelSecurity"
          },
          "type": "array"
        },
        "sink": {
          "$ref": "#/definitions/Sink"
        },
        "sql": {
          "description": "Main SQL request to execute (do not forget to prefix table names with the database name to avoid conflicts)",
          "type": "string"
        },
        "table": {
          "description": "Dataset Name in output Area (Will be the Table name in Hive & BigQuery)",
          "type": "string"
        },
        "write": {
          "$ref": "#/definitions/WriteMode"
        }
      },
      "required": ["domain", "table", "write"],
      "type": "object"
    },
    "Domain": {
      "anyOf": [
        {
          "required": ["name", "tables"]
        },
        {
          "required": ["name", "tableRefs"]
        }
      ],
      "properties": {
        "ack": {
          "description": "Moved to metadata section since 0.2.8",
          "type": "string"
        },
        "comment": {
          "description": "Domain Description (free text)",
          "type": "string"
        },
        "directory": {
          "description": "Moved to metadata section since 0.2.8",
          "type": "string"
        },
        "extensions": {
          "description": "Moved to metadata section since 0.2.8",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "metadata": {
          "$ref": "#/definitions/Metadata"
        },
        "name": {
          "description": "Domain name. Make sure you use a name that may be used as a folder name on the target storage.\n                   - When using HDFS or Cloud Storage,  files once ingested are stored in a sub-directory named after the domain name.\n                   - When used with BigQuery, files are ingested and sorted in tables under a dataset named after the domain name.",
          "type": "string"
        },
        "rename": {
          "description": "If present, the attribute is renamed with this name",
          "type": "string"
        },
        "tableRefs": {
          "description": "List of files containing the schemas. Should start with an '_' and be located in the same folder.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "tables": {
          "description": "List of schemas for each dataset in this domain.\nA domain usually contains multiple schemas. Each schema defining how the contents of the input file should be parsed.\nSee Schema for more details.",
          "items": {
            "$ref": "#/definitions/Table"
          },
          "type": "array"
        }
      },
      "type": "object"
    },
    "Engine": {
      "description": "SPARK or BQ. Default value is SPARK.",
      "oneOf": [
        {
          "const": "BQ",
          "description": ""
        },
        {
          "const": "SPARK",
          "description": ""
        }
      ],
      "type": "string"
    },
    "Format": {
      "description": "DSV by default. Supported file formats are :\\n- DSV : Delimiter-separated values file. Delimiter value is specified in the \"separator\" field.\\n- POSITION : FIXED format file where values are located at an exact position in each line.\\n- SIMPLE_JSON : For optimisation purpose, we differentiate JSON with top level values from JSON\\n  with deep level fields. SIMPLE_JSON are JSON files with top level fields only.\\n- JSON :  Deep JSON file. Use only when your json documents contain subdocuments, otherwise prefer to\\n  use SIMPLE_JSON since it is much faster.\\n- XML : XML files",
      "oneOf": [
        {
          "const": "DSV",
          "description": ""
        },
        {
          "const": "POSITION",
          "description": ""
        },
        {
          "const": "JSON",
          "description": ""
        },
        {
          "const": "ARRAY_JSON",
          "description": ""
        },
        {
          "const": "SIMPLE_JSON",
          "description": "Simple Json is made of a single level attributes of simple types (no array or map or sub objects)"
        },
        {
          "const": "XML",
          "description": ""
        }
      ],
      "type": "string"
    },
    "IndexMapping": {
      "oneOf": [
        {
          "const": "text",
          "description": ""
        },
        {
          "const": "keyword",
          "description": ""
        },
        {
          "const": "long",
          "description": ""
        },
        {
          "const": "integer",
          "description": ""
        },
        {
          "const": "short",
          "description": ""
        },
        {
          "const": "byte",
          "description": ""
        },
        {
          "const": "double",
          "description": ""
        },
        {
          "const": "float",
          "description": ""
        },
        {
          "const": "half_float",
          "description": ""
        },
        {
          "const": "scaled_float",
          "description": ""
        },
        {
          "const": "date",
          "description": ""
        },
        {
          "const": "boolean",
          "description": ""
        },
        {
          "const": "binary",
          "description": ""
        },
        {
          "const": "integer_rang",
          "description": ""
        },
        {
          "const": "float_range",
          "description": ""
        },
        {
          "const": "long_range",
          "description": ""
        },
        {
          "const": "double_range",
          "description": ""
        },
        {
          "const": "date_range",
          "description": ""
        },
        {
          "const": "geo_point",
          "description": ""
        },
        {
          "const": "geo_shape",
          "description": ""
        },
        {
          "const": "ip",
          "description": ""
        },
        {
          "const": "completion",
          "description": ""
        },
        {
          "const": "token_count",
          "description": ""
        },
        {
          "const": "object",
          "description": ""
        },
        {
          "const": "array",
          "description": ""
        }
      ],
      "type": "string"
    },
    "JDBCSchema": {
      "properties": {
        "catalog": {
          "description": "Optional catalog name in the source database",
          "type": "string"
        },
        "connection": {
          "description": "Connection name as defined in the connections section of the application.conf file",
          "type": "string"
        },
        "schema": {
          "description": "Database schema where source tables are located",
          "type": "string"
        },
        "tableTypes": {
          "description": "One or many of the predefined table types",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "tables": {
          "description": "List of tables to extract",
          "items": {
            "$ref": "#/definitions/JDBCTable"
          },
          "type": "array"
        },
        "template": {
          "description": "Metadata to use for the generated YAML file.",
          "type": "string"
        }
      },
      "required": ["connection", "tables"],
      "type": "object"
    },
    "JDBCSchemas": {
      "properties": {
        "jdbcSchemas": {
          "description": "List database connections to use to extract the data",
          "items": {
            "$ref": "#/definitions/JDBCSchema"
          },
          "type": "array"
        }
      },
      "required": ["name"],
      "type": "object"
    },
    "JDBCTable": {
      "properties": {
        "columns": {
          "description": "List of columns to extract. All columns by default.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "name": {
          "description": "table name. Set to '*' to extract all tables",
          "type": "string"
        }
      },
      "required": ["name"],
      "type": "object"
    },
    "MapArrayOfString": {
      "additionalProperties": {
        "items": {
          "type": "string"
        },
        "type": "array"
      },
      "type": "object"
    },
    "MapString": {
      "additionalProperties": {
        "type": "string"
      },
      "type": "object"
    },
    "MergeOptions": {
      "properties": {
        "delete": {
          "description": "Optional valid sql condition on the incoming dataset. Use renamed column here.",
          "type": "string"
        },
        "key": {
          "description": "list of attributes to join existing with incoming dataset. Use renamed columns here.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "queryFilter": {
          "type": "string"
        },
        "timestamp": {
          "description": "Timestamp column used to identify last version, if not specified currently ingested row is considered the last",
          "type": "string"
        }
      },
      "required": ["key"],
      "type": "object"
    },
    "Metadata": {
      "properties": {
        "ack": {
          "description": "Ack extension used for each file. \".ack\" if not specified.\nFiles are moved to the pending folder only once a file with the same name as the source file and with this extension is present.\nTo move a file without requiring an ack file to be present, set explicitly this property to the empty string value \"\".",
          "type": "string"
        },
        "array": {
          "description": "Is the json stored as a single object array ? false by default. This means that by default we have on json document per line.",
          "type": "boolean"
        },
        "clustering": {
          "description": "List of attributes to use for clustering",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "directory": {
          "description": "Folder on the local filesystem where incoming files are stored.\n Typically, this folder will be scanned periodically to move the dataset to the cluster for ingestion.\n                     Files located in this folder are moved to the pending folder for ingestion by the \"import\" command.",
          "type": "string"
        },
        "encoding": {
          "description": "UTF-8 if not specified.",
          "type": "string"
        },
        "escape": {
          "description": "escaping char '\\' by default",
          "type": "string"
        },
        "extensions": {
          "description": "recognized filename extensions. json, csv, dsv, psv are recognized by default.\nOnly files with these extensions will be moved to the pending folder.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "format": {
          "$ref": "#/definitions/Format"
        },
        "ignore": {
          "description": "Pattern to ignore or UDF to apply to ignore some lines",
          "type": "string"
        },
        "mode": {
          "$ref": "#/definitions/Mode"
        },
        "multiline": {
          "description": "are json objects on a single line or multiple line ? Single by default.  false means single. false also means faster",
          "type": "boolean"
        },
        "options": {
          "$ref": "#/definitions/MapString",
          "description": "Options to add to the spark reader"
        },
        "partition": {
          "$ref": "#/definitions/Partition"
        },
        "quote": {
          "description": "The String quote char, '\"' by default",
          "type": "string"
        },
        "schedule": {
          "$ref": "#/definitions/MapString",
          "description": "Scheduler Options"
        },
        "separator": {
          "description": "the values delimiter,  ';' by default value may be a multichar string starting from Spark3",
          "type": "string"
        },
        "sink": {
          "$ref": "#/definitions/Sink"
        },
        "validator": {
          "description": "Row validator to use",
          "type": "string"
        },
        "withHeader": {
          "description": "does the dataset has a header ? true bu default",
          "type": "boolean"
        },
        "write": {
          "$ref": "#/definitions/WriteMode",
          "description": "Write mode, APPEND by default"
        },
        "xml": {
          "$ref": "#/definitions/MapString",
          "description": "com.databricks.spark.xml options to use (eq. rowTag)"
        }
      },
      "type": "object"
    },
    "Mode": {
      "description": "FILE mode by default.\\nFILE and STREAM are the two accepted values.\\nFILE is currently the only supported mode.",
      "oneOf": [
        {
          "const": "FILE",
          "description": ""
        },
        {
          "const": "STREAM",
          "description": ""
        },
        {
          "const": "FILE_AND_STREAM",
          "description": ""
        }
      ],
      "type": "string"
    },
    "Partition": {
      "description": "Partition columns, no partitioning by default",
      "properties": {
        "attributes": {
          "items": {
            "description": "Attributes used to partition de dataset.",
            "type": "string"
          },
          "type": "array"
        },
        "sampling": {
          "description": "0.0 means no sampling, > 0  && < 1 means sample dataset, >=1 absolute number of partitions.",
          "type": "number"
        }
      },
      "required": [],
      "type": "object"
    },
    "Position": {
      "properties": {
        "first": {
          "type": "number"
        },
        "last": {
          "type": "number"
        }
      },
      "required": ["first", "last"],
      "type": "object"
    },
    "PrimitiveType": {
      "oneOf": [
        {
          "const": "string",
          "description": ""
        },
        {
          "const": "long",
          "description": ""
        },
        {
          "const": "int",
          "description": ""
        },
        {
          "const": "short",
          "description": ""
        },
        {
          "const": "double",
          "description": ""
        },
        {
          "const": "boolean",
          "description": ""
        },
        {
          "const": "byte",
          "description": ""
        },
        {
          "const": "date",
          "description": ""
        },
        {
          "const": "timestamp",
          "description": ""
        },
        {
          "const": "decimal",
          "description": ""
        },
        {
          "const": "struct",
          "description": ""
        }
      ],
      "type": "string"
    },
    "RowLevelSecurity": {
      "description": "Row level security policy to apply to the output data.",
      "properties": {
        "description": {
          "description": "Description for this access policy",
          "type": "string"
        },
        "grants": {
          "description": "user / groups / service accounts to which this security level is applied.\nex : user:me@mycompany.com,group:group@mycompany.com,serviceAccount:mysa@google-accounts.com",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "name": {
          "description": "This Row Level Security unique name",
          "type": "string"
        },
        "predicate": {
          "description": "The condition that goes to the WHERE clause and limit the visible rows.",
          "type": "string"
        }
      },
      "required": ["name", "grants"],
      "type": "object"
    },
    "Sink": {
      "properties": {
        "batchSize": {
          "description": "JDBC: Batch size of each JDBC bulk insert",
          "type": "number"
        },
        "clustering": {
          "description": "FS or BQ: List of attributes to use for clustering",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "connection": {
          "description": "JDBC: Connection String",
          "type": "string"
        },
        "days": {
          "description": "BQ: Number of days before this table is set as expired and deleted. Never by default.",
          "type": "number"
        },
        "extension": {
          "description": "FS: File extension",
          "type": "string"
        },
        "format": {
          "description": "FS: File format",
          "type": "string"
        },
        "id": {
          "description": "ES: Attribute to use as id of the document. Generated by Elasticsearch if not specified.",
          "type": "string"
        },
        "location": {
          "description": "BQ: Database location (EU, US, ...)",
          "type": "string"
        },
        "name": {
          "description": "Once ingested, files may be sinked to BigQuery, Elasticsearch or any JDBC compliant Database.",
          "type": "string"
        },
        "options": {
          "$ref": "#/definitions/MapString",
          "description": "spark  options to use"
        },
        "partition": {
          "$ref": "#/definitions/Partition",
          "description": "FS or BQ: List of partition attributes"
        },
        "partitions": {
          "description": "JDBC: Number of Spark partitions",
          "type": "number"
        },
        "requirePartitionFilter": {
          "description": "BQ: Should be require a partition filter on every request ? No by default.",
          "type": "boolean"
        },
        "timestamp": {
          "description": "ES or BQ: The timestamp column to use for table partitioning if any. No partitioning by default\\nES:Timestamp field format as expected by Elasticsearch (\"{beginTs|yyyy.MM.dd}\" for example).",
          "type": "string"
        },
        "type": {
          "$ref": "#/definitions/SinkType",
          "description": "Once ingested, files may be sinked to BigQuery, Elasticsearch or any JDBC compliant Database."
        }
      },
      "required": ["type"],
      "type": "object"
    },
    "SinkType": {
      "description": "Where to sink the data",
      "oneOf": [
        {
          "const": "NONE",
          "description": "Don't sink. This is the default"
        },
        {
          "const": "JBDC",
          "description": "dataset will be sinked to a JDBC Database. See JdbcSink"
        },
        {
          "const": "BQ",
          "description": "Dataset is sinked to BigQuery. See BigQuerySink"
        },
        {
          "const": "ES",
          "description": "Dataset is indexed into Elasticsearch. See EsSink below"
        },
        {
          "const": "FS",
          "description": "Sink to Filesystem"
        },
        {
          "const": "KAFKA",
          "description": "Sink to Kafka"
        }
      ],
      "type": "string"
    },
    "Table": {
      "properties": {
        "acl": {
          "description": "Map of rolename -> List[Users].",
          "items": {
            "$ref": "#/definitions/AccessControlEntry"
          },
          "type": "array"
        },
        "assertions": {
          "$ref": "#/definitions/MapString",
          "description": "Assertions to check after Load / Transform has succeeded"
        },
        "attributes": {
          "description": "Attributes parsing rules.",
          "items": {
            "$ref": "#/definitions/Attribute"
          },
          "type": "array"
        },
        "comment": {
          "description": "free text",
          "type": "string"
        },
        "merge": {
          "$ref": "#/definitions/MergeOptions"
        },
        "metadata": {
          "$ref": "#/definitions/Metadata",
          "description": "Dataset metadata"
        },
        "name": {
          "description": "Schema name, must be unique among all the schemas belonging to the same domain.\n  *                     Will become the hive table name On Premise or BigQuery Table name on GCP.",
          "type": "string"
        },
        "pattern": {
          "description": "filename pattern to which this schema must be applied.\n  *                     This instructs the framework to use this schema to parse any file with a filename that match this pattern.",
          "type": "string"
        },
        "postsql": {
          "description": "Reserved for future use.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "presql": {
          "description": "Reserved for future use.",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "primaryKey": {
          "description": "List of columns that make up the primary key",
          "items": {
            "type": "string"
          },
          "type": "array"
        },
        "rename": {
          "description": "If present, the attribute is renamed with this name",
          "type": "string"
        },
        "rls": {
          "description": " Row level security on this schema.",
          "items": {
            "$ref": "#/definitions/RowLevelSecurity"
          },
          "type": "array"
        },
        "tags": {
          "description": "Set of string to attach to this Schema",
          "items": {
            "type": "string"
          },
          "type": "array"
        }
      },
      "type": "object"
    },
    "TableType": {
      "oneOf": [
        {
          "const": "TABLE",
          "description": ""
        },
        {
          "const": "VIEW",
          "description": ""
        },
        {
          "const": "SYSTEM TABLE",
          "description": ""
        },
        {
          "const": "GLOBAL TEMPORARY",
          "description": ""
        },
        {
          "const": "LOCAL TEMPORARY",
          "description": ""
        },
        {
          "const": "ALIAS",
          "description": ""
        },
        {
          "const": "SYNONYM",
          "description": ""
        }
      ],
      "type": "string"
    },
    "Trim": {
      "oneOf": [
        {
          "const": "LEFT",
          "description": ""
        },
        {
          "const": "RIGHT",
          "description": ""
        },
        {
          "const": "BOTH",
          "description": ""
        },
        {
          "const": "NONE",
          "description": ""
        }
      ],
      "type": "string"
    },
    "Type": {
      "properties": {
        "comment": {
          "type": "string"
        },
        "ddlMapping": {
          "$ref": "#/definitions/MapString",
          "description": "Configure here the type mapping for each datawarehouse.\\nWill be used when inferring DDL from schema."
        },
        "indexMapping": {
          "type": "string"
        },
        "name": {
          "type": "string"
        },
        "pattern": {
          "type": "string"
        },
        "primitiveType": {
          "$ref": "#/definitions/PrimitiveType"
        },
        "sample": {
          "type": "string"
        },
        "zone": {
          "description": "Useful for timestamp / dates",
          "type": "string"
        }
      },
      "required": ["name", "pattern", "primitiveType"],
      "type": "object"
    },
    "UserType": {
      "oneOf": [
        {
          "const": "SA",
          "description": ""
        },
        {
          "const": "USER",
          "description": ""
        },
        {
          "const": "GROUP",
          "description": ""
        }
      ],
      "type": "string"
    },
    "WriteMode": {
      "description": "Append to or overwrite existing data",
      "oneOf": [
        {
          "const": "OVERWRITE",
          "description": ""
        },
        {
          "const": "APPEND",
          "description": ""
        },
        {
          "const": "ERROR_IF_EXISTS",
          "description": ""
        },
        {
          "const": "IGNORE",
          "description": ""
        }
      ],
      "type": "string"
    }
  },
  "description": "JSON Schema for Starlake Data Pipeline",
  "oneOf": [
    {
      "required": ["extract"]
    },
    {
      "required": ["load"]
    },
    {
      "required": ["transform"]
    },
    {
      "required": ["views"]
    },
    {
      "required": ["assertions"]
    },
    {
      "required": ["env"]
    },
    {
      "required": ["types"]
    },
    {
      "required": ["tables"]
    }
  ],
  "properties": {
    "assertions": {
      "$ref": "#/definitions/MapString",
      "description": "Assertions library defined as a map name(params) -> sql request that should return 0 record"
    },
    "env": {
      "$ref": "#/definitions/MapString"
    },
    "extract": {
      "$ref": "#/definitions/JDBCSchemas"
    },
    "load": {
      "$ref": "#/definitions/Domain"
    },
    "schemas": {
      "description": "List of schemas for each dataset in this domain.\nA domain usually contains multiple schemas. Each schema defining how the contents of the input file should be parsed.\nSee Schema for more details.",
      "items": {
        "$ref": "#/definitions/Table"
      },
      "type": "array"
    },
    "transform": {
      "$ref": "#/definitions/AutoJobDesc"
    },
    "types": {
      "items": {
        "$ref": "#/definitions/Type"
      },
      "type": "array"
    },
    "views": {
      "$ref": "#/definitions/MapString"
    }
  },
  "title": "Starlake Data Pipeline",
  "type": "object"
}
